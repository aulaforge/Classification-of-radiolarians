{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "weighted-victor",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-01T11:52:10.876199Z",
     "iopub.status.busy": "2021-06-01T11:52:10.874218Z",
     "iopub.status.idle": "2021-06-01T11:52:10.886542Z",
     "shell.execute_reply": "2021-06-01T11:52:10.885852Z",
     "shell.execute_reply.started": "2021-06-01T10:01:30.123964Z"
    },
    "papermill": {
     "duration": 0.028086,
     "end_time": "2021-06-01T11:52:10.886695",
     "exception": false,
     "start_time": "2021-06-01T11:52:10.858609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-barcelona",
   "metadata": {
    "papermill": {
     "duration": 0.008743,
     "end_time": "2021-06-01T11:52:10.904901",
     "exception": false,
     "start_time": "2021-06-01T11:52:10.896158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We define our model with the MobileNetV2 model that is defined in the Tensorflow library. I used the article linked below to help me.\n",
    "\n",
    "We then compile the model with the correct accuracy and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fatty-payday",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T11:52:10.933229Z",
     "iopub.status.busy": "2021-06-01T11:52:10.932252Z",
     "iopub.status.idle": "2021-06-01T11:52:21.229415Z",
     "shell.execute_reply": "2021-06-01T11:52:21.228566Z",
     "shell.execute_reply.started": "2021-06-01T10:01:30.132724Z"
    },
    "papermill": {
     "duration": 10.315712,
     "end_time": "2021-06-01T11:52:21.229581",
     "exception": false,
     "start_time": "2021-06-01T11:52:10.913869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Inspired by https://medium.com/hackernoon/tf-serving-keras-mobilenetv2-632b8d92983c\n",
    "# and https://github.com/malnakli/ML/blob/master/tf_serving_keras_mobilenetv2/main.ipynb\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "   \n",
    "\n",
    "target_size = 60\n",
    "\n",
    "def build_model( ):\n",
    "    input_tensor = Input(shape=(target_size, target_size, 3))\n",
    "    base_model = MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=(target_size, target_size, 3),\n",
    "        pooling='avg')\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True  # trainable has to be false in order to freeze the layers\n",
    "            \n",
    "    op = Dense(256, activation='relu')(base_model.output)\n",
    "    op = Dropout(.25)(op)\n",
    "        \n",
    "        ##\n",
    "        # softmax: calculates a probability for every possible class.\n",
    "        #\n",
    "        # activation='softmax': return the highest probability;\n",
    "        # for example, if 'Coat' is the highest probability then the result would be \n",
    "        # something like [0,0,0,0,1,0,0,0,0,0] with 1 in index 5 indicate 'Coat' in our case.\n",
    "        ##\n",
    "    output_tensor = Dense(10, activation='softmax')(op)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    \n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-surge",
   "metadata": {
    "papermill": {
     "duration": 0.010203,
     "end_time": "2021-06-01T11:52:21.250584",
     "exception": false,
     "start_time": "2021-06-01T11:52:21.240381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We load the fashion MNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coordinated-midwest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T11:52:21.280195Z",
     "iopub.status.busy": "2021-06-01T11:52:21.279093Z",
     "iopub.status.idle": "2021-06-01T11:52:24.303860Z",
     "shell.execute_reply": "2021-06-01T11:52:24.304413Z",
     "shell.execute_reply.started": "2021-06-01T10:01:31.121935Z"
    },
    "papermill": {
     "duration": 3.043134,
     "end_time": "2021-06-01T11:52:24.304626",
     "exception": false,
     "start_time": "2021-06-01T11:52:21.261492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchSize = 64\n",
    "\n",
    "# Load the fashion-mnist train data and test data\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "    \n",
    "    \n",
    "    \n",
    "norm_x_train = x_train.astype('float32') / 255\n",
    "norm_x_test = x_test.astype('float32') / 255\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "   \n",
    "encoded_y_train = to_categorical(y_train, num_classes=10, dtype='float32')\n",
    "encoded_y_test = to_categorical(y_test, num_classes=10, dtype='float32')\n",
    "   \n",
    "del x_train\n",
    "del x_test\n",
    "del y_train\n",
    "del y_test\n",
    "gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-order",
   "metadata": {
    "papermill": {
     "duration": 0.017085,
     "end_time": "2021-06-01T11:52:24.339286",
     "exception": false,
     "start_time": "2021-06-01T11:52:24.322201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here is the function used on the data set to make it a correct input for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "clean-respondent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T11:52:24.380572Z",
     "iopub.status.busy": "2021-06-01T11:52:24.379619Z",
     "iopub.status.idle": "2021-06-01T11:52:24.932640Z",
     "shell.execute_reply": "2021-06-01T11:52:24.931900Z",
     "shell.execute_reply.started": "2021-06-01T10:01:31.910525Z"
    },
    "papermill": {
     "duration": 0.57612,
     "end_time": "2021-06-01T11:52:24.932859",
     "exception": false,
     "start_time": "2021-06-01T11:52:24.356739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from tensorflow.image import resize, grayscale_to_rgb\n",
    "    \n",
    "    \n",
    "def preprocess_images(x):\n",
    "\n",
    "        \n",
    "    first = True\n",
    "    data= []\n",
    "      \n",
    "    batch = np.asarray(x)\n",
    "    batch = batch[..., np.newaxis]\n",
    "    batch = resize(batch, (target_size, target_size))\n",
    "           \n",
    "    batch = grayscale_to_rgb(tf.convert_to_tensor(batch))\n",
    "    batch = np.asarray(batch)\n",
    "           \n",
    "    return (tf.convert_to_tensor(batch.astype(np.float32)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-graphics",
   "metadata": {
    "papermill": {
     "duration": 0.015854,
     "end_time": "2021-06-01T11:52:24.965326",
     "exception": false,
     "start_time": "2021-06-01T11:52:24.949472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We apply the function on the training data set and we train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "political-agency",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T11:52:25.149725Z",
     "iopub.status.busy": "2021-06-01T11:52:25.148789Z",
     "iopub.status.idle": "2021-06-01T11:53:01.148749Z",
     "shell.execute_reply": "2021-06-01T11:53:01.149413Z",
     "shell.execute_reply.started": "2021-06-01T10:01:31.918245Z"
    },
    "papermill": {
     "duration": 36.168093,
     "end_time": "2021-06-01T11:53:01.149680",
     "exception": false,
     "start_time": "2021-06-01T11:52:24.981587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 15s 34ms/step - loss: 1.1111 - categorical_accuracy: 0.6473\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 0.5076 - categorical_accuracy: 0.8364\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.3777 - categorical_accuracy: 0.8675\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.4014 - categorical_accuracy: 0.8723\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.3542 - categorical_accuracy: 0.8779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_x_train = preprocess_images(norm_x_train)\n",
    "\n",
    "    \n",
    "    \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((norm_x_train, encoded_y_train)).shuffle(norm_x_train.shape[0], reshuffle_each_iteration=True).batch(batchSize)\n",
    "\n",
    "    \n",
    "del norm_x_train\n",
    "del encoded_y_train\n",
    "gc.collect()\n",
    "\n",
    "    \n",
    "model.fit(\n",
    "        train_dataset,\n",
    "        batch_size = batchSize,\n",
    "        steps_per_epoch=100,\n",
    "        verbose=1,\n",
    "        epochs=5)\n",
    "    \n",
    "\n",
    "del train_dataset\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-wildlife",
   "metadata": {
    "papermill": {
     "duration": 0.107268,
     "end_time": "2021-06-01T11:53:01.366175",
     "exception": false,
     "start_time": "2021-06-01T11:53:01.258907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We apply the function on our test set and we evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prompt-discretion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T11:53:01.613441Z",
     "iopub.status.busy": "2021-06-01T11:53:01.612079Z",
     "iopub.status.idle": "2021-06-01T11:53:05.528211Z",
     "shell.execute_reply": "2021-06-01T11:53:05.527659Z",
     "shell.execute_reply.started": "2021-06-01T10:02:06.656689Z"
    },
    "papermill": {
     "duration": 4.054055,
     "end_time": "2021-06-01T11:53:05.528363",
     "exception": false,
     "start_time": "2021-06-01T11:53:01.474308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 3s 11ms/step - loss: 0.9976 - categorical_accuracy: 0.7922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9975534677505493, 0.792187511920929]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_x_test = preprocess_images(norm_x_test)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((norm_x_test, encoded_y_test)).shuffle(norm_x_test.shape[0], reshuffle_each_iteration=True).batch(batchSize)\n",
    "del norm_x_test\n",
    "gc.collect()\n",
    "    \n",
    "\n",
    "model.evaluate(\n",
    "        test_dataset,\n",
    "        steps=100,\n",
    "        verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 65.864723,
   "end_time": "2021-06-01T11:53:08.739291",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-01T11:52:02.874568",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
